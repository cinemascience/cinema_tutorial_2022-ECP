{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the cinemasci tutorial workflow.  \n",
    "\n",
    "This workflow starts by importing the cinemasci python module and creating a viewer object.  \n",
    "\n",
    "There is an already-existing Cinema database: `data/nyx_volume.cdb` in the `data/` directory that will be loaded into the viewer.  \n",
    "\n",
    "Give it a few seconds to start the viewer and load the database..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cinemasci\n",
    "import cinemasci.pynb\n",
    "import os\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the database in the built-in viewer using the sliders\n",
    "\n",
    "Run this cell and then take a minute to explore the Cinema database with the viewer sliders.  The data is from the Nyx Cosmology simulation and shows the formation of dark matter halos over time.  The variable shown is log(baryon density).  The database images show the simulation from different phi/theta angles with five selected time steps.  \n",
    "\n",
    "Note that the databases included in this workflow are quite small to make this workflow quicker.  A Cinema database generated by a large scale simulation may contain thousands of images and much finer-grained angle divisions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78eae94f03234585b7948def11dd90c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(border='0px solid black', width='98%')), HBox(children=(Output(layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a viewer object\n",
    "viewer = cinemasci.pynb.CinemaViewer()\n",
    "viewer.setUIValues({'image size': 200})\n",
    "viewer.hideParameterControl('producer')\n",
    "\n",
    "my_cdb = \"data/nyx_volume.cdb\"\n",
    "viewer.load(my_cdb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll do an example analysis workflow\n",
    "\n",
    "The next cell brings in a Cinema database of 2D slices from the Nyx simulation and opens the database of slices in the viewer object.  Note that the slider values, which are drawn from the Cinema database columns, now only have slice number and time step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e0fa94b871457d84d2998db2ce57d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Output(layout=Layout(border='0px solid black', width='98%')), HBox(children=(Output(layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Note: assumes previous cell has been run\n",
    "import shutil\n",
    "\n",
    "clean_slice = \"data/nyx_clean_slice.cdb\"\n",
    "\n",
    "# create a viewer object\n",
    "viewerS = cinemasci.pynb.CinemaViewer()\n",
    "viewerS.setUIValues({'image size': 200})\n",
    "viewerS.load(clean_slice)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a Cinema database directory for the analysis output\n",
    "\n",
    "First there is a check to see if the the workflow has been previously run; some some cleanup is done so that we start from the unanalyzed images (clean_slice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New CDB will go into:  ./data/nyx_new_slice.cdb/\n"
     ]
    }
   ],
   "source": [
    "# Are we rerunning the workflow?  If so, remove old output database to generate new images and data.csv.\n",
    "new_cdb = \"nyx_new_slice.cdb/\"\n",
    "path_dir = \"./data/\"\n",
    "cdb_path = os.path.join(path_dir, new_cdb) \n",
    "print ('New CDB will go into: ', cdb_path)\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(cdb_path)\n",
    "except OSError as e:#\n",
    "    print(\"Need a working CDB: %s : %s\" % (cdb_path, \"Creating nyx_slice.cdb\"))\n",
    "shutil.copytree(clean_slice, cdb_path) \n",
    "# Load the data.csv from the nyx_slices CDB into a dataframe\n",
    "data_csv = cdb_path + \"data.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image-based analysis leveraging Python libraries\n",
    "\n",
    "Jupyter notebooks are becoming a common analysis approach for scientists.  This workflow takes the Cinema database of image slices from the Nyx simulation and performs some basic analysis on the images.  The Cinema database is read in as a pandas dataframe; the skimage library is used to calculate standard statisical quantities; OpenCV library is used to find countours and edges in the images.  These analyses generate output variables and the OpenCV analysis generates additional images with the new contours.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from skimage import color\n",
    "from skimage import feature\n",
    "from skimage.measure import shannon_entropy\n",
    "import numpy as np\n",
    "\n",
    "dfslices = pd.read_csv(data_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need a set of lists to create the new columns for the dataframe / eventual updated CDB\n",
    "imgMean = []\n",
    "imgStDev = []\n",
    "imgShEntropy = []\n",
    "grayFILE = []\n",
    "cannyFILE = []\n",
    "contoursFILE = []\n",
    "\n",
    "# Set up variables for the Canny edge detection\n",
    "lower_threshold = 5\n",
    "upper_threshold = 200\n",
    "sobel_size = 3\n",
    "bins = 131072\n",
    "\n",
    "# Set up variables for the contours\n",
    "cthreshold = 45\n",
    "thickness = 2\n",
    "color = [200,200,200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making new images, please wait...\n",
      "New images now available\n"
     ]
    }
   ],
   "source": [
    "# Cycle through the CDB slices\n",
    "print ('Making new images, please wait...')\n",
    "for f in dfslices['FILE'] :\n",
    "    # Load each image and convert to a grayscale image\n",
    "#    imgpath = my_slice_cdb + f\n",
    "    imgpath = cdb_path + f\n",
    "    src = cv2.imread(imgpath)   # original color image\n",
    "    imggray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY ) # grayscale image\n",
    "    \n",
    "    # Save grayscale image to disk and save (relative) path/name to list of grayscale image names\n",
    "    grayfile = imgpath.replace('.png' ,'_gray.png')\n",
    "    cv2.imwrite(grayfile, imggray)\n",
    "    grayFILE.append(f.replace('.png' ,'_gray.png'))\n",
    "    \n",
    "    # Calculate some basic statistics on the grayscale images and add to respective lists\n",
    "    imgMean.append(np.mean(io.imread(grayfile), (0,1)) )\n",
    "    imgStDev.append(np.std(io.imread(grayfile), (0,1)) )\n",
    "    imgShEntropy.append(shannon_entropy(imggray))\n",
    "    \n",
    "    # Do some Canny edge detection, again saving the new image and adding new path/name to a list\n",
    "    imgCannyEdges = cv2.Canny(imggray, lower_threshold, upper_threshold, apertureSize=sobel_size, L2gradient=False)\n",
    "    cannyfile = imgpath.replace('.png', '_canny_edge.png')\n",
    "    cv2.imwrite(cannyfile, imgCannyEdges)\n",
    "    cannyFILE.append(f.replace('.png', '_canny_edge.png'))\n",
    "    \n",
    "    # Find some contours, again saving the new image and adding new path/name to a list\n",
    "    ret, binary = cv2.threshold(imggray, cthreshold, 255, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    imgContours = cv2.drawContours(src, contours, -1, (color[2], color[1], color[0]), thickness)\n",
    "    contoursfile = imgpath.replace('.png' ,'_contours.png')\n",
    "    cv2.imwrite(contoursfile, imgContours)\n",
    "    contoursFILE.append(f.replace('.png', '_contours.png'))\n",
    " \n",
    "print (\"New images now available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the new Cinema database\n",
    "\n",
    "In the next cell, the new statistical quantities and the new images with the contour are added to the dataframe.  The dataframe is written out to the `data.csv` file for the new Cinema database.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the dataframe with the new columns and reorder to fit Cinema Specification\n",
    "dfslices['FILE_gray'] = grayFILE\n",
    "dfslices['FILE_canny_edge'] = cannyFILE\n",
    "dfslices['Mean'] = imgMean\n",
    "dfslices['ShannonEntropy'] = imgShEntropy\n",
    "dfslices['StdDev'] = imgStDev\n",
    "dfslices['FILE_contours'] = contoursFILE\n",
    "\n",
    "dfslices = dfslices[['timestep', 'slice', 'Mean', 'StdDev', 'ShannonEntropy', \n",
    "                     'FILE', 'FILE_gray', 'FILE_canny_edge', 'FILE_contours']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write out the new data.csv \n",
    "dfslices.to_csv(data_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View all the Cinema databases\n",
    "\n",
    "Using the OS sytem library, an already-existing html file is opened in Firefox so that all these Cinema databases can be explored using the browser-based Cinema:View and Cinema:Explorer viewers.  \n",
    "\n",
    "This workflow involved three Cinema databases: the `nyx_volume.cdb` database that has images spanning phi/theta; the original `nyx_clean_slice.cdb` which has the two original slices of 2D Nyx data; and the output `nyx_new_slices.cdb` that includes the statistical analysis variables and the new images with the OpenCV contours.  \n",
    "\n",
    "Take some time to explore these databases in the viewers.  Cinema:Explorer uses a parallel coordinates plot approach to interactively explore a Cinema database.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "darwin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (platform )\n",
    "if (platform == 'darwin') :\n",
    "    os.system('open -a Firefox ./nyx_databases.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
